import streamlit as st
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.core.settings import Settings
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

st.set_page_config(page_title="Vivek Lean Leadership Coach", layout="wide")
st.title("ðŸ§  Vivek Lean Leadership Coach")
st.markdown("Your personalized lean & six sigma AI â€“ trained on 50+ core books and statistical texts.")

# Password protection
password = st.text_input("Enter password to continue:", type="password")
if password != "Priyav@1983!":
    st.stop()

# Load vector index
@st.cache_resource
def load_index():
    Settings.llm = OpenAI(model="gpt-3.5-turbo")
    Settings.embed_model = OpenAIEmbedding()
    documents = SimpleDirectoryReader("books").load_data()
    return VectorStoreIndex.from_documents(documents)

index = load_index()

# Query input
query = st.text_input("Ask your lean or six sigma question:")
if query:
    st.write("Generating answer from Vivek's RAG library...")
    response = index.as_query_engine().query(query)
    st.success(response.response)